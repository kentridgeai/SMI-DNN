{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d108a34-d1cd-4404-926a-ed8bd80956a5",
   "metadata": {},
   "source": [
    "### Experiments for Section 4.2: Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5cf146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import models\n",
    "import datasets\n",
    "import entropy_estimators as ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7837ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf9c21",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4716bb",
   "metadata": {},
   "source": [
    "### 1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0a46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['dataset'] = 'MNIST'\n",
    "cfg['model'] = 'MLP'\n",
    "cfg['width'] = [1024,1024,1024,1024]\n",
    "cfg['noise_ratio'] = 0.0\n",
    "cfg['optimizer'] = 'SGD'\n",
    "cfg['learning_rate'] = 0.01\n",
    "cfg['batch_size']    = 32\n",
    "cfg['n_epochs'] = 1000\n",
    "\n",
    "cfg['dropout'] = []\n",
    "cfg['weight_decay'] = []\n",
    "cfg['batch_norm'] = []\n",
    "cfg['noise_ratio'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d7bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directory generalization/MLP_1024-1024-1024-1024_MNIST_SGD/run_1\n"
     ]
    }
   ],
   "source": [
    "run = 1\n",
    "arch =  '-'.join(map(str,cfg['width']))\n",
    "exp_name = 'generalization/'+cfg['model']+'_'+arch+'_'+cfg['dataset']+'_'+cfg['optimizer']\n",
    "cfg['exp_name'] = exp_name + '/run_%d'%(run)\n",
    "if not os.path.exists(cfg['exp_name']):\n",
    "    print(\"Making directory\", cfg['exp_name'])\n",
    "    os.makedirs(cfg['exp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d0bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = cfg['exp_name'] + '/config.json'\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd03fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = datasets.get_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b29340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,962,890\n",
      "Trainable params: 3,962,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.get_model(cfg, trn)\n",
    "model.save(cfg['exp_name']+\"/model_initial\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eedd34c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.2453 - accuracy: 0.9254\n",
      "Training Accuracy: 0.971\n",
      "Set best train accuracy to: 0.971\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0865 - accuracy: 0.9736\n",
      "Training Accuracy: 0.985\n",
      "Set best train accuracy to: 0.985\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0557 - accuracy: 0.9826\n",
      "Training Accuracy: 0.988\n",
      "Set best train accuracy to: 0.988\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0380 - accuracy: 0.9878\n",
      "Training Accuracy: 0.991\n",
      "Set best train accuracy to: 0.991\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0286 - accuracy: 0.9909\n",
      "Training Accuracy: 0.995\n",
      "Set best train accuracy to: 0.995\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0191 - accuracy: 0.9943\n",
      "Training Accuracy: 0.996\n",
      "Set best train accuracy to: 0.996\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0154 - accuracy: 0.9950\n",
      "Training Accuracy: 0.997\n",
      "Set best train accuracy to: 0.997\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0134 - accuracy: 0.9957\n",
      "Training Accuracy: 0.994\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0097 - accuracy: 0.9970\n",
      "Training Accuracy: 0.996\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0071 - accuracy: 0.9978\n",
      "Training Accuracy: 1.000\n",
      "Set best train accuracy to: 1.000\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0052 - accuracy: 0.9986\n",
      "Training Accuracy: 0.999\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Training Accuracy: 0.998\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0061 - accuracy: 0.9979\n",
      "Training Accuracy: 0.999\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0032 - accuracy: 0.9991\n",
      "Training Accuracy: 1.000\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 5.4764e-04 - accuracy: 0.9999\n",
      "Training Accuracy: 1.000\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 5.1169e-04 - accuracy: 0.9999\n",
      "Training Accuracy: 1.000\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 1.7620e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 7.5478e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 4.8938e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 3.5915e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 3.1344e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 2.7887e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.5118e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.2948e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.1102e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.9568e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.8239e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.7090e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 1.6087e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.5282e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 1.4547e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 1.3888e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 1.3286e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.2736e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.2229e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.1761e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.1331e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.0926e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.0552e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 1.0239e-05 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 9.9441e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 9.6649e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 9.4012e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 9.1501e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 8.9163e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 8.6908e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 8.4776e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 8.2748e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 8.0823e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.9158e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 7.7555e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.6030e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.4551e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.3138e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.1768e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 7.0448e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 57/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 6.9199e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 58/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 6.7977e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 6.6794e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 6.5776e-06 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "class CustomEarlyStopping(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0, threshold=1):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best_trn_acc = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        trn_acc = self.model.evaluate(trn.X, trn.Y, batch_size=32, verbose=0)[1]       \n",
    "        print('Training Accuracy: %0.03f'%trn_acc)\n",
    "        if np.greater(np.round(trn_acc,3), np.round(self.best_trn_acc,3)):\n",
    "            print('Set best train accuracy to: %0.03f'%trn_acc)\n",
    "            self.best_trn_acc = trn_acc\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "custom_ES = CustomEarlyStopping(patience=50)\n",
    "lr_decay = ReduceLROnPlateau(monitor='accuracy', factor=0.9, patience=10, verbose=1)\n",
    "\n",
    "r = model.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 1, \n",
    "              batch_size = cfg['batch_size'],\n",
    "              epochs = cfg['n_epochs'],\n",
    "              callbacks = [custom_ES, lr_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1610c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(cfg['exp_name']+\"/model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691acdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the train and test set:\n",
      "60000/60000 [==============================] - 3s 55us/step\n",
      "10000/10000 [==============================] - 1s 55us/step\n",
      "Train loss = 0.002; Train accuracy = 1.000\n",
      "Test loss = 0.075; Test accuracy = 0.984\n",
      "Saving generalization/MLP_1024-1024-1024-1024_MNIST_SGD/run_1/metrics\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "print('Evaluating the model on the train and test set:')\n",
    "trn_results = model.evaluate(trn.X, trn.Y, batch_size=32, verbose=1)\n",
    "train_loss = trn_results[0]\n",
    "train_acc = trn_results[1]\n",
    "tst_results = model.evaluate(tst.X, tst.Y, batch_size=32, verbose=1)\n",
    "test_loss = tst_results[0]\n",
    "test_acc = tst_results[1]\n",
    "print('Train loss = %0.03f; Train accuracy = %0.03f'%(train_loss, train_acc))\n",
    "print('Test loss = %0.03f; Test accuracy = %0.03f'%(test_loss, test_acc))\n",
    "\n",
    "metrics={}\n",
    "metrics['train_loss'] = train_loss\n",
    "metrics['train_acc'] = train_acc\n",
    "metrics['test_loss'] = test_loss\n",
    "metrics['test_acc'] = test_acc\n",
    "\n",
    "fname = cfg['exp_name']+'/metrics'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(metrics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc3fc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: SI(T;Y)=0.282\n",
      "Layer 2: SI(T;Y)=0.486\n",
      "Layer 3: SI(T;Y)=0.849\n",
      "Layer 4: SI(T;Y)=1.163\n",
      "Layer 5: SI(T;Y)=1.480\n",
      "Saving generalization/MLP_1024-1024-1024-1024_MNIST_SGD/run_1/smi\n"
     ]
    }
   ],
   "source": [
    "smi_all = []\n",
    "\n",
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "count = 0\n",
    "for l, layer in enumerate(model.layers):\n",
    "    if hasattr(layer, 'kernel'):\n",
    "        count += 1\n",
    "        int_model = keras.Model(inputs=model.inputs, outputs=model.layers[l].output)\n",
    "        activity = int_model.predict(trn.X[:10000])\n",
    "        smi = ee.compute_smi(x=activity, y=trn.y[:10000], m=1000)\n",
    "        smi_all.append(smi)\n",
    "        print(f'Layer {count}: SI(T;Y)={smi:.3f}')\n",
    "\n",
    "fname = cfg['exp_name']+'/smi'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(smi_all, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc479c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving generalization/MLP_1024-1024-1024-1024_MNIST_SGD/run_1/smi_pen\n"
     ]
    }
   ],
   "source": [
    "fname = cfg['exp_name']+'/smi_pen'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(smi_all[-2], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19171c13",
   "metadata": {},
   "source": [
    "### 2. Vary Dropout Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22c12eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['dataset'] = 'MNIST'\n",
    "cfg['model'] = 'MLP'\n",
    "cfg['width'] = [1024,1024,1024,1024]\n",
    "cfg['optimizer'] = 'SGD'\n",
    "cfg['learning_rate'] = 0.01\n",
    "cfg['batch_size']    = 32\n",
    "cfg['n_epochs'] = 1000\n",
    "\n",
    "cfg['dropout'] = [0.2,0.2,0.2,0.2]\n",
    "cfg['weight_decay'] = []\n",
    "cfg['batch_norm'] = []\n",
    "cfg['noise_ratio'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5537ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directory generalization/MLP_MNIST/MLP_1024-1024-1024-1024_MNIST_SGD_LabelNoise_0.01/run_1\n"
     ]
    }
   ],
   "source": [
    "run = 1\n",
    "arch =  '-'.join(map(str,cfg['width']))\n",
    "exp_name = 'generalization/'+cfg['model']+'_'+cfg['dataset']+'/'+cfg['model']+'_'+arch+'_'+cfg['dataset']+'_'+cfg['optimizer']\n",
    "if len(cfg['dropout']) > 0:\n",
    "    dropout =  '-'.join(map(str,cfg['dropout']))\n",
    "    exp_name += '_Dropout_'+dropout\n",
    "cfg['exp_name'] = exp_name + '/run_%d'%(run)\n",
    "if not os.path.exists(cfg['exp_name']):\n",
    "    print(\"Making directory\", cfg['exp_name'])\n",
    "    os.makedirs(cfg['exp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6c38d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = cfg['exp_name'] + '/config.json'\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5831a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = datasets.get_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6f390e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,962,890\n",
      "Trainable params: 3,962,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.get_model(cfg, trn)\n",
    "model.save(cfg['exp_name']+\"/model_initial\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23939186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.3122 - accuracy: 0.9183\n",
      "Training Accuracy: 0.966\n",
      "Set best train accuracy to: 0.966\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.1606 - accuracy: 0.9648\n",
      "Training Accuracy: 0.973\n",
      "Set best train accuracy to: 0.973\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1257 - accuracy: 0.9747\n",
      "Training Accuracy: 0.980\n",
      "Set best train accuracy to: 0.980\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1037 - accuracy: 0.9800\n",
      "Training Accuracy: 0.984\n",
      "Set best train accuracy to: 0.984\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0876 - accuracy: 0.9839\n",
      "Training Accuracy: 0.982\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0778 - accuracy: 0.9850\n",
      "Training Accuracy: 0.985\n",
      "Set best train accuracy to: 0.985\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0667 - accuracy: 0.9870\n",
      "Training Accuracy: 0.990\n",
      "Set best train accuracy to: 0.990\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0575 - accuracy: 0.9884\n",
      "Training Accuracy: 0.986\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0513 - accuracy: 0.9890\n",
      "Training Accuracy: 0.990\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0470 - accuracy: 0.9897\n",
      "Training Accuracy: 0.993\n",
      "Set best train accuracy to: 0.993\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0410 - accuracy: 0.9905\n",
      "Training Accuracy: 0.992\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0366 - accuracy: 0.9912\n",
      "Training Accuracy: 0.993\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0295 - accuracy: 0.9929\n",
      "Training Accuracy: 0.993\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0340 - accuracy: 0.9914\n",
      "Training Accuracy: 0.991\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0336 - accuracy: 0.9909\n",
      "Training Accuracy: 0.995\n",
      "Set best train accuracy to: 0.995\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0244 - accuracy: 0.9938\n",
      "Training Accuracy: 0.994\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0195 - accuracy: 0.9950\n",
      "Training Accuracy: 0.994\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0250 - accuracy: 0.9933\n",
      "Training Accuracy: 0.994\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0214 - accuracy: 0.9941\n",
      "Training Accuracy: 0.997\n",
      "Set best train accuracy to: 0.997\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0195 - accuracy: 0.9943\n",
      "Training Accuracy: 0.996\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0146 - accuracy: 0.9962\n",
      "Training Accuracy: 0.998\n",
      "Set best train accuracy to: 0.998\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0158 - accuracy: 0.9956\n",
      "Training Accuracy: 0.995\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0147 - accuracy: 0.9955\n",
      "Training Accuracy: 0.997\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0122 - accuracy: 0.9969\n",
      "Training Accuracy: 0.997\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0111 - accuracy: 0.9972\n",
      "Training Accuracy: 0.998\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0067 - accuracy: 0.9982\n",
      "Training Accuracy: 0.999\n",
      "Set best train accuracy to: 0.999\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Training Accuracy: 0.999\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Training Accuracy: 0.999\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0038 - accuracy: 0.9989\n",
      "Training Accuracy: 0.999\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Training Accuracy: 0.999\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Training Accuracy: 0.999\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Training Accuracy: 0.999\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Training Accuracy: 0.999\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Training Accuracy: 1.000\n",
      "Set best train accuracy to: 1.000\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Training Accuracy: 0.999\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Training Accuracy: 1.000\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Training Accuracy: 1.000\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Training Accuracy: 1.000\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Training Accuracy: 0.999\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Training Accuracy: 1.000\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 9.3597e-04 - accuracy: 0.9997\n",
      "Training Accuracy: 0.999\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Training Accuracy: 0.999\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0215 - accuracy: 0.9938\n",
      "Training Accuracy: 0.996\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0167 - accuracy: 0.9946\n",
      "Training Accuracy: 0.997\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Training Accuracy: 0.999\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Training Accuracy: 0.999\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0025 - accuracy: 0.9992\n",
      "Training Accuracy: 0.999\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Training Accuracy: 0.999\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Training Accuracy: 0.999\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Training Accuracy: 1.000\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Training Accuracy: 0.993\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0064 - accuracy: 0.9984\n",
      "Training Accuracy: 0.999\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Training Accuracy: 1.000\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Training Accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "class CustomEarlyStopping(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0, threshold=1):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best_trn_acc = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        trn_acc = self.model.evaluate(trn.X, trn.Y, batch_size=32, verbose=0)[1]       \n",
    "        print('Training Accuracy: %0.03f'%trn_acc)\n",
    "        if np.greater(np.round(trn_acc,3), np.round(self.best_trn_acc,3)):\n",
    "            print('Set best train accuracy to: %0.03f'%trn_acc)\n",
    "            self.best_trn_acc = trn_acc\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "custom_ES = CustomEarlyStopping(patience=20)\n",
    "lr_decay = ReduceLROnPlateau(monitor='accuracy', factor=0.9, patience=10, verbose=1)\n",
    "\n",
    "r = model.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 1, \n",
    "              batch_size = cfg['batch_size'],\n",
    "              epochs = cfg['n_epochs'],\n",
    "              callbacks = [custom_ES, lr_decay])\n",
    "\n",
    "model.save(cfg['exp_name']+\"/model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "daf83a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the train and test set:\n",
      "60000/60000 [==============================] - 3s 56us/step\n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "Train loss = 0.001; Train accuracy = 1.000\n",
      "Test loss = 0.095; Test accuracy = 0.984\n",
      "Saving generalization/MLP_MNIST/MLP_1024-1024-1024-1024_MNIST_SGD_LabelNoise_0.01/run_1/metrics\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "print('Evaluating the model on the train and test set:')\n",
    "trn_results = model.evaluate(trn.X, trn.Y, batch_size=32, verbose=1)\n",
    "train_loss = trn_results[0]\n",
    "train_acc = trn_results[1]\n",
    "tst_results = model.evaluate(tst.X, tst.Y, batch_size=32, verbose=1)\n",
    "test_loss = tst_results[0]\n",
    "test_acc = tst_results[1]\n",
    "print('Train loss = %0.03f; Train accuracy = %0.03f'%(train_loss, train_acc))\n",
    "print('Test loss = %0.03f; Test accuracy = %0.03f'%(test_loss, test_acc))\n",
    "\n",
    "metrics={}\n",
    "metrics['train_loss'] = train_loss\n",
    "metrics['train_acc'] = train_acc\n",
    "metrics['test_loss'] = test_loss\n",
    "metrics['test_acc'] = test_acc\n",
    "\n",
    "fname = cfg['exp_name']+'/metrics'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(metrics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "71f40a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMI:0.637\n",
      "Saving generalization/MLP_MNIST/MLP_1024-1024-1024-1024_MNIST_SGD_LabelNoise_0.01/run_1/smi_pen\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "int_model = keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
    "activity = int_model.predict(trn.X[:10000], batch_size=32)\n",
    "smi = ee.compute_smi(x=activity, y=trn.y[:10000], m=1000)\n",
    "print(f'SMI:{smi:.3f}')\n",
    "\n",
    "fname = cfg['exp_name']+'/smi_pen'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(smi, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c26224",
   "metadata": {},
   "source": [
    "### 3. Vary Label Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f916903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['dataset'] = 'MNIST'\n",
    "cfg['model'] = 'MLP'\n",
    "cfg['width'] = [1024,1024,1024,1024]\n",
    "cfg['optimizer'] = 'SGD'\n",
    "cfg['learning_rate'] = 0.01\n",
    "cfg['batch_size']    = 32\n",
    "cfg['n_epochs'] = 1000\n",
    "\n",
    "cfg['dropout'] = []\n",
    "cfg['weight_decay'] = []\n",
    "cfg['batch_norm'] = []\n",
    "cfg['noise_ratio'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d232c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directory generalization/MLP_MNIST/MLP_1024-1024-1024-1024_MNIST_SGD_Dropout_0.2-0.2-0.2-0.2/run_1\n"
     ]
    }
   ],
   "source": [
    "run = 1\n",
    "arch =  '-'.join(map(str,cfg['width']))\n",
    "exp_name = 'generalization/'+cfg['model']+'_'+cfg['dataset']+'/'+cfg['model']+'_'+arch+'_'+cfg['dataset']+'_'+cfg['optimizer']\n",
    "if cfg['noise_ratio'] > 0:\n",
    "    exp_name += '_LabelNoise_'+str(cfg['noise_ratio'])\n",
    "cfg['exp_name'] = exp_name + '/run_%d'%(run)\n",
    "if not os.path.exists(cfg['exp_name']):\n",
    "    print(\"Making directory\", cfg['exp_name'])\n",
    "    os.makedirs(cfg['exp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa11afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = cfg['exp_name'] + '/config.json'\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eff052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = datasets.get_dataset(cfg)\n",
    "\n",
    "if cfg['noise_ratio'] > 0:\n",
    "    with open(cfg['exp_name']+'/noisy_trn', 'wb') as f:\n",
    "        pickle.dump(trn._asdict(), f, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(cfg['exp_name']+'/tst', 'wb') as f:\n",
    "        pickle.dump(tst._asdict(), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd916d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,962,890\n",
      "Trainable params: 3,962,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.get_model(cfg, trn)\n",
    "model.save(cfg['exp_name']+\"/model_initial\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf65ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.2881 - accuracy: 0.9108\n",
      "Training Accuracy: 0.963\n",
      "Set best train accuracy to: 0.963\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.1172 - accuracy: 0.9639\n",
      "Training Accuracy: 0.978\n",
      "Set best train accuracy to: 0.978\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0844 - accuracy: 0.9733\n",
      "Training Accuracy: 0.986\n",
      "Set best train accuracy to: 0.986\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0660 - accuracy: 0.9793\n",
      "Training Accuracy: 0.989\n",
      "Set best train accuracy to: 0.989\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0515 - accuracy: 0.9836\n",
      "Training Accuracy: 0.992\n",
      "Set best train accuracy to: 0.992\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0451 - accuracy: 0.9860\n",
      "Training Accuracy: 0.991\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0368 - accuracy: 0.9882\n",
      "Training Accuracy: 0.995\n",
      "Set best train accuracy to: 0.995\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0343 - accuracy: 0.9890\n",
      "Training Accuracy: 0.993\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0288 - accuracy: 0.9906\n",
      "Training Accuracy: 0.994\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0243 - accuracy: 0.9920\n",
      "Training Accuracy: 0.997\n",
      "Set best train accuracy to: 0.997\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0233 - accuracy: 0.9922\n",
      "Training Accuracy: 0.997\n",
      "Epoch 12/1000\n",
      "55360/60000 [==========================>...] - ETA: 0s - loss: 0.0197 - accuracy: 0.9935"
     ]
    }
   ],
   "source": [
    "class CustomEarlyStopping(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0, threshold=1):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best_trn_acc = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        trn_acc = self.model.evaluate(trn.X, trn.Y, batch_size=32, verbose=0)[1]       \n",
    "        print('Training Accuracy: %0.03f'%trn_acc)\n",
    "        if np.greater(np.round(trn_acc,3), np.round(self.best_trn_acc,3)):\n",
    "            print('Set best train accuracy to: %0.03f'%trn_acc)\n",
    "            self.best_trn_acc = trn_acc\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "custom_ES = CustomEarlyStopping(patience=20)\n",
    "lr_decay = ReduceLROnPlateau(monitor='accuracy', factor=0.9, patience=10, verbose=1)\n",
    "\n",
    "r = model.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 1, \n",
    "              batch_size = cfg['batch_size'],\n",
    "              epochs = cfg['n_epochs'],\n",
    "              callbacks = [custom_ES, lr_decay])\n",
    "\n",
    "model.save(cfg['exp_name']+\"/model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce20165",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "if cfg['noise_ratio'] > 0:\n",
    "    Dataset = namedtuple('Dataset',['X','Y','y'])\n",
    "    with open(cfg['exp_name']+'/noisy_trn', 'rb') as f:\n",
    "        trn = Dataset(**pickle.load(f))\n",
    "    with open(cfg['exp_name']+'/tst', 'rb') as f:\n",
    "        tst = Dataset(**pickle.load(f))\n",
    "\n",
    "print('Evaluating the model on the train and test set:')\n",
    "trn_results = model.evaluate(trn.X, trn.Y, batch_size=32, verbose=1)\n",
    "train_loss = trn_results[0]\n",
    "train_acc = trn_results[1]\n",
    "tst_results = model.evaluate(tst.X, tst.Y, batch_size=32, verbose=1)\n",
    "test_loss = tst_results[0]\n",
    "test_acc = tst_results[1]\n",
    "print('Train loss = %0.03f; Train accuracy = %0.03f'%(train_loss, train_acc))\n",
    "print('Test loss = %0.03f; Test accuracy = %0.03f'%(test_loss, test_acc))\n",
    "\n",
    "metrics={}\n",
    "metrics['train_loss'] = train_loss\n",
    "metrics['train_acc'] = train_acc\n",
    "metrics['test_loss'] = test_loss\n",
    "metrics['test_acc'] = test_acc\n",
    "\n",
    "fname = cfg['exp_name']+'/metrics'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(metrics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a36ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg['noise_ratio'] > 0:\n",
    "    Dataset = namedtuple('Dataset',['X','Y','y'])\n",
    "    with open(cfg['exp_name']+'/noisy_trn', 'rb') as f:\n",
    "        trn = Dataset(**pickle.load(f))\n",
    "        \n",
    "noisy_label = trn.Y.argmax(1)\n",
    "\n",
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "int_model = keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
    "activity = int_model.predict(trn.X[:10000], batch_size=32)\n",
    "smi = ee.compute_smi(x=activity, y=noisy_label[:10000], m=1000)\n",
    "print(f'SMI:{smi:.3f}')\n",
    "\n",
    "fname = cfg['exp_name']+'/smi_pen'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(smi, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56038cfa",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e30a4d",
   "metadata": {},
   "source": [
    "### 1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e018865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['dataset'] = 'Fashion_MNIST'\n",
    "cfg['model'] = 'CNN_Global'\n",
    "cfg['width'] = [512,512,512,512]\n",
    "cfg['optimizer'] = 'SGD'\n",
    "cfg['learning_rate'] = 0.01\n",
    "cfg['batch_size']    = 32\n",
    "cfg['n_epochs'] = 1000\n",
    "cfg['n_train'] = None\n",
    "\n",
    "cfg['dropout'] = []\n",
    "cfg['weight_decay'] = []\n",
    "cfg['batch_norm'] = [] # set to [True,True,True,True] for use of batch norm in all layers\n",
    "cfg['noise_ratio'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f086dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directory generalization/CNN_Global_Fashion_MNIST/CNN_Global_512-512-512-512_Fashion_MNIST_SGD_BatchNorm_True-True-True-True/run_1\n"
     ]
    }
   ],
   "source": [
    "run = 1\n",
    "arch =  '-'.join(map(str,cfg['width']))\n",
    "exp_name = 'generalization/'+cfg['model']+'_'+cfg['dataset']+'/'+cfg['model']+'_'+arch+'_'+cfg['dataset']+'_'+cfg['optimizer']\n",
    "if cfg['n_train'] is not None:\n",
    "    exp_name += '_'+str(cfg['n_train'])\n",
    "if len(cfg['batch_norm']) > 0:\n",
    "    bn =  '-'.join(map(str,cfg['batch_norm']))\n",
    "    exp_name += '_BatchNorm_'+bn\n",
    "if len(cfg['dropout']) > 0:\n",
    "    dropout =  '-'.join(map(str,cfg['dropout']))\n",
    "    exp_name += '_Dropout_'+dropout\n",
    "if cfg['noise_ratio'] > 0:\n",
    "    exp_name += '_LabelNoise_'+str(cfg['noise_ratio'])\n",
    "cfg['exp_name'] = exp_name + '/run_%d'%(run)\n",
    "if not os.path.exists(cfg['exp_name']):\n",
    "    print(\"Making directory\", cfg['exp_name'])\n",
    "    os.makedirs(cfg['exp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48d424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = cfg['exp_name'] + '/config.json'\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf899b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = datasets.get_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a505e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 10)          5130      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,097,866\n",
      "Trainable params: 7,093,770\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.get_model(cfg, trn)\n",
    "model.save(cfg['exp_name']+\"/model_initial\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18eb42fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 30s 503us/step - loss: 0.4424 - accuracy: 0.8388\n",
      "Training Accuracy: 0.805\n",
      "Set best train accuracy to: 0.805\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.2996 - accuracy: 0.8909\n",
      "Training Accuracy: 0.908\n",
      "Set best train accuracy to: 0.908\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.2520 - accuracy: 0.9083\n",
      "Training Accuracy: 0.925\n",
      "Set best train accuracy to: 0.925\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.2158 - accuracy: 0.9218\n",
      "Training Accuracy: 0.934\n",
      "Set best train accuracy to: 0.934\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 0.1887 - accuracy: 0.9316\n",
      "Training Accuracy: 0.946\n",
      "Set best train accuracy to: 0.946\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.1625 - accuracy: 0.9420\n",
      "Training Accuracy: 0.944\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.1391 - accuracy: 0.9492\n",
      "Training Accuracy: 0.961\n",
      "Set best train accuracy to: 0.961\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 0.1178 - accuracy: 0.9590\n",
      "Training Accuracy: 0.965\n",
      "Set best train accuracy to: 0.965\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.0980 - accuracy: 0.9648\n",
      "Training Accuracy: 0.969\n",
      "Set best train accuracy to: 0.969\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 0.0818 - accuracy: 0.9707\n",
      "Training Accuracy: 0.981\n",
      "Set best train accuracy to: 0.981\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0653 - accuracy: 0.9780\n",
      "Training Accuracy: 0.972\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 32s 541us/step - loss: 0.0517 - accuracy: 0.9822\n",
      "Training Accuracy: 0.987\n",
      "Set best train accuracy to: 0.987\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0417 - accuracy: 0.9864\n",
      "Training Accuracy: 0.988\n",
      "Set best train accuracy to: 0.988\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 33s 555us/step - loss: 0.0307 - accuracy: 0.9907\n",
      "Training Accuracy: 0.994\n",
      "Set best train accuracy to: 0.994\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0261 - accuracy: 0.9919\n",
      "Training Accuracy: 0.996\n",
      "Set best train accuracy to: 0.996\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.0190 - accuracy: 0.9947\n",
      "Training Accuracy: 0.995\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.0144 - accuracy: 0.9962\n",
      "Training Accuracy: 0.998\n",
      "Set best train accuracy to: 0.998\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.0089 - accuracy: 0.9982\n",
      "Training Accuracy: 0.998\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 25s 425us/step - loss: 0.0059 - accuracy: 0.9991\n",
      "Training Accuracy: 0.999\n",
      "Set best train accuracy to: 0.999\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 0.0042 - accuracy: 0.9994\n",
      "Training Accuracy: 1.000\n",
      "Set best train accuracy to: 1.000\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.0027 - accuracy: 0.9998\n",
      "Training Accuracy: 1.000\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Training Accuracy: 1.000\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Training Accuracy: 1.000\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 8.5298e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 6.9123e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 6.1783e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 5.9998e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 5.5027e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 4.9513e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 4.9440e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 4.1997e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 3.8577e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 3.7213e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 25s 422us/step - loss: 3.4911e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 3.2648e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 2.9092e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 3.0415e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 2.7312e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 2.6437e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 3.0038e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 2.6848e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 2.3797e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 2.3198e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 2.2700e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 2.0984e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 2.0432e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 1.9751e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 2.1286e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 1.8857e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 1.9268e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 1.8062e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 1.8115e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 1.5867e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 1.6658e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 1.6469e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 57/1000\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 1.7665e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 58/1000\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 1.6168e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 1.5525e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 1.4476e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 61/1000\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 1.3658e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 62/1000\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 1.4765e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 63/1000\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 1.5570e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 64/1000\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 1.3901e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 65/1000\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 1.3584e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 66/1000\n",
      "60000/60000 [==============================] - 26s 433us/step - loss: 1.3369e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 67/1000\n",
      "60000/60000 [==============================] - 26s 433us/step - loss: 1.3220e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 68/1000\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 1.2528e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 69/1000\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 1.2815e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 70/1000\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 1.2344e-04 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "class CustomEarlyStopping(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0, threshold=1):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best_trn_acc = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        trn_acc = self.model.evaluate(trn.X, trn.Y, batch_size=32, verbose=0)[1]       \n",
    "        print('Training Accuracy: %0.03f'%trn_acc)\n",
    "        if np.greater(np.round(trn_acc,3), np.round(self.best_trn_acc,3)):\n",
    "            print('Set best train accuracy to: %0.03f'%trn_acc)\n",
    "            self.best_trn_acc = trn_acc\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "custom_ES = CustomEarlyStopping(patience=50)\n",
    "lr_decay = ReduceLROnPlateau(monitor='accuracy', factor=0.9, patience=10, verbose=1)\n",
    "\n",
    "r = model.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 1, \n",
    "              batch_size = cfg['batch_size'],\n",
    "              epochs = cfg['n_epochs'],\n",
    "              callbacks = [custom_ES, lr_decay])\n",
    "\n",
    "model.save(cfg['exp_name']+\"/model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4b762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the train and test set:\n",
      "60000/60000 [==============================] - 10s 160us/step\n",
      "10000/10000 [==============================] - 2s 167us/step\n",
      "Train loss = 0.003; Train accuracy = 1.000\n",
      "Test loss = 0.313; Test accuracy = 0.923\n",
      "Saving generalization/CNN_Global_Fashion_MNIST/CNN_Global_512-512-512-512_Fashion_MNIST_SGD_BatchNorm_True-True-True-True/run_1/metrics\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "print('Evaluating the model on the train and test set:')\n",
    "trn_results = model.evaluate(trn.X, trn.Y, batch_size=32, verbose=1)\n",
    "train_loss = trn_results[0]\n",
    "train_acc = trn_results[1]\n",
    "tst_results = model.evaluate(tst.X, tst.Y, batch_size=32, verbose=1)\n",
    "test_loss = tst_results[0]\n",
    "test_acc = tst_results[1]\n",
    "print('Train loss = %0.03f; Train accuracy = %0.03f'%(train_loss, train_acc))\n",
    "print('Test loss = %0.03f; Test accuracy = %0.03f'%(test_loss, test_acc))\n",
    "\n",
    "metrics={}\n",
    "metrics['train_loss'] = train_loss\n",
    "metrics['train_acc'] = train_acc\n",
    "metrics['test_loss'] = test_loss\n",
    "metrics['test_acc'] = test_acc\n",
    "\n",
    "fname = cfg['exp_name']+'/metrics'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(metrics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c212bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMI:0.198\n",
      "Saving generalization/CNN_Global_Fashion_MNIST/CNN_Global_512-512-512-512_Fashion_MNIST_SGD_BatchNorm_True-True-True-True/run_1/smi\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "int_model = keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
    "activity = int_model.predict(trn.X[:10000], batch_size=32)\n",
    "if len(activity.shape) > 2:\n",
    "    activity = activity.reshape(activity.shape[0],-1)\n",
    "smi = ee.compute_smi(x=activity, y=trn.y[:10000], m=1000)\n",
    "print(f'SMI:{smi:.3f}')\n",
    "\n",
    "fname = cfg['exp_name']+'/smi'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(smi, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smi_all = []\n",
    "\n",
    "# model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "# count = 0\n",
    "# for l, layer in enumerate(model.layers):\n",
    "#     if isinstance(layer, keras.layers.Activation) or isinstance(layer, keras.layers.GlobalAveragePooling2D):\n",
    "#         count += 1\n",
    "#         int_model = keras.Model(inputs=model.inputs, outputs=model.layers[l].output)\n",
    "#         activity = int_model.predict(trn.X[:10000], batch_size=32)\n",
    "#         if len(activity.shape) > 2:\n",
    "#             activity = activity.reshape(activity.shape[0],-1)\n",
    "#         smi = ee.compute_smi(x=activity, y=trn.y[:10000], m=1000)\n",
    "#         smi_all.append(smi)\n",
    "#         print(f'Layer {count}: SI(T;Y)={smi:.3f}')\n",
    "\n",
    "# fname = cfg['exp_name']+'/smi'\n",
    "# print(\"Saving\", fname)\n",
    "# with open(fname, 'wb') as f:\n",
    "#     pickle.dump(smi_all, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec86d2",
   "metadata": {},
   "source": [
    "### 2. Vary Dropout Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b4e890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['dataset'] = 'Fashion_MNIST'\n",
    "cfg['model'] = 'CNN_Global'\n",
    "cfg['width'] = [512,512,512,512]\n",
    "cfg['noise_ratio'] = 0.0\n",
    "cfg['optimizer'] = 'SGD'\n",
    "cfg['learning_rate'] = 0.01\n",
    "cfg['batch_size']    = 32\n",
    "cfg['n_epochs'] = 1000\n",
    "cfg['n_train'] = None\n",
    "\n",
    "cfg['dropout'] = [0.4,0.4,0.4,0.4]\n",
    "cfg['weight_decay'] = []\n",
    "cfg['batch_norm'] = [True,True,True,True]\n",
    "cfg['noise_ratio'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9eec5833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directory generalization/CNN_Global_Fashion_MNIST/CNN_Global_512-512-512-512_Fashion_MNIST_SGD_BatchNorm_True-True-True-True_Dropout_0.4-0.4-0.4-0.4/run_1\n"
     ]
    }
   ],
   "source": [
    "run = 1\n",
    "arch =  '-'.join(map(str,cfg['width']))\n",
    "exp_name = 'generalization/'+cfg['model']+'_'+cfg['dataset']+'/'+cfg['model']+'_'+arch+'_'+cfg['dataset']+'_'+cfg['optimizer']\n",
    "if len(cfg['batch_norm']) > 0:\n",
    "    bn =  '-'.join(map(str,cfg['batch_norm']))\n",
    "    exp_name += '_BatchNorm_'+bn\n",
    "if len(cfg['dropout']) > 0:\n",
    "    dropout =  '-'.join(map(str,cfg['dropout']))\n",
    "    exp_name += '_Dropout_'+dropout\n",
    "cfg['exp_name'] = exp_name + '/run_%d'%(run)\n",
    "if not os.path.exists(cfg['exp_name']):\n",
    "    print(\"Making directory\", cfg['exp_name'])\n",
    "    os.makedirs(cfg['exp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3e89a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = cfg['exp_name'] + '/config.json'\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9dbd3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = datasets.get_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e493bd4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 13, 13, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 13, 13, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 11, 11, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 3, 3, 10)          5130      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,097,866\n",
      "Trainable params: 7,093,770\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.get_model(cfg, trn)\n",
    "model.save(cfg['exp_name']+\"/model_initial\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "895e1696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.5410 - accuracy: 0.7987\n",
      "Training Accuracy: 0.858\n",
      "Set best train accuracy to: 0.858\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.3832 - accuracy: 0.8609\n",
      "Training Accuracy: 0.877\n",
      "Set best train accuracy to: 0.877\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 0.3358 - accuracy: 0.8769\n",
      "Training Accuracy: 0.894\n",
      "Set best train accuracy to: 0.894\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.3082 - accuracy: 0.8875\n",
      "Training Accuracy: 0.901\n",
      "Set best train accuracy to: 0.901\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.2861 - accuracy: 0.8954\n",
      "Training Accuracy: 0.893\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 32s 527us/step - loss: 0.2741 - accuracy: 0.9003\n",
      "Training Accuracy: 0.918\n",
      "Set best train accuracy to: 0.918\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.2583 - accuracy: 0.9051\n",
      "Training Accuracy: 0.914\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 29s 481us/step - loss: 0.2462 - accuracy: 0.9094\n",
      "Training Accuracy: 0.910\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.2335 - accuracy: 0.9139\n",
      "Training Accuracy: 0.904\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.2270 - accuracy: 0.9170\n",
      "Training Accuracy: 0.934\n",
      "Set best train accuracy to: 0.934\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.2185 - accuracy: 0.9199\n",
      "Training Accuracy: 0.940\n",
      "Set best train accuracy to: 0.940\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.2131 - accuracy: 0.9217\n",
      "Training Accuracy: 0.934\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.2043 - accuracy: 0.9242\n",
      "Training Accuracy: 0.929\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1948 - accuracy: 0.9271\n",
      "Training Accuracy: 0.944\n",
      "Set best train accuracy to: 0.944\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1898 - accuracy: 0.9300\n",
      "Training Accuracy: 0.949\n",
      "Set best train accuracy to: 0.949\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1820 - accuracy: 0.9329\n",
      "Training Accuracy: 0.936\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.1772 - accuracy: 0.9340\n",
      "Training Accuracy: 0.952\n",
      "Set best train accuracy to: 0.952\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1698 - accuracy: 0.9384\n",
      "Training Accuracy: 0.950\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1648 - accuracy: 0.9395\n",
      "Training Accuracy: 0.960\n",
      "Set best train accuracy to: 0.960\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1599 - accuracy: 0.9417\n",
      "Training Accuracy: 0.966\n",
      "Set best train accuracy to: 0.966\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1530 - accuracy: 0.9436\n",
      "Training Accuracy: 0.967\n",
      "Set best train accuracy to: 0.967\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.1496 - accuracy: 0.9444\n",
      "Training Accuracy: 0.964\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1454 - accuracy: 0.9456\n",
      "Training Accuracy: 0.968\n",
      "Set best train accuracy to: 0.968\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1423 - accuracy: 0.9482\n",
      "Training Accuracy: 0.973\n",
      "Set best train accuracy to: 0.973\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1343 - accuracy: 0.9499\n",
      "Training Accuracy: 0.973\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.1319 - accuracy: 0.9510\n",
      "Training Accuracy: 0.972\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1252 - accuracy: 0.9541\n",
      "Training Accuracy: 0.971\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1217 - accuracy: 0.9551\n",
      "Training Accuracy: 0.977\n",
      "Set best train accuracy to: 0.977\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.1211 - accuracy: 0.9550\n",
      "Training Accuracy: 0.977\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1149 - accuracy: 0.9582\n",
      "Training Accuracy: 0.982\n",
      "Set best train accuracy to: 0.982\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.1102 - accuracy: 0.9590\n",
      "Training Accuracy: 0.984\n",
      "Set best train accuracy to: 0.984\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.1087 - accuracy: 0.9603\n",
      "Training Accuracy: 0.982\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.1056 - accuracy: 0.9613\n",
      "Training Accuracy: 0.977\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0993 - accuracy: 0.9625\n",
      "Training Accuracy: 0.980\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0968 - accuracy: 0.9643\n",
      "Training Accuracy: 0.986\n",
      "Set best train accuracy to: 0.986\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0973 - accuracy: 0.9634\n",
      "Training Accuracy: 0.988\n",
      "Set best train accuracy to: 0.988\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0915 - accuracy: 0.9662\n",
      "Training Accuracy: 0.985\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0892 - accuracy: 0.9670\n",
      "Training Accuracy: 0.990\n",
      "Set best train accuracy to: 0.990\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.0866 - accuracy: 0.9674\n",
      "Training Accuracy: 0.990\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0847 - accuracy: 0.9693\n",
      "Training Accuracy: 0.989\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0833 - accuracy: 0.9692\n",
      "Training Accuracy: 0.984\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0797 - accuracy: 0.9702\n",
      "Training Accuracy: 0.991\n",
      "Set best train accuracy to: 0.991\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0756 - accuracy: 0.9720\n",
      "Training Accuracy: 0.989\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0739 - accuracy: 0.9734\n",
      "Training Accuracy: 0.993\n",
      "Set best train accuracy to: 0.993\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0726 - accuracy: 0.9731\n",
      "Training Accuracy: 0.983\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0693 - accuracy: 0.9745\n",
      "Training Accuracy: 0.989\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0673 - accuracy: 0.9750\n",
      "Training Accuracy: 0.994\n",
      "Set best train accuracy to: 0.994\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0668 - accuracy: 0.9757\n",
      "Training Accuracy: 0.991\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0638 - accuracy: 0.9762\n",
      "Training Accuracy: 0.995\n",
      "Set best train accuracy to: 0.995\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0610 - accuracy: 0.9772\n",
      "Training Accuracy: 0.994\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0620 - accuracy: 0.9773\n",
      "Training Accuracy: 0.995\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0576 - accuracy: 0.9792\n",
      "Training Accuracy: 0.993\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0560 - accuracy: 0.9789\n",
      "Training Accuracy: 0.995\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0567 - accuracy: 0.9792\n",
      "Training Accuracy: 0.997\n",
      "Set best train accuracy to: 0.997\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0542 - accuracy: 0.9804\n",
      "Training Accuracy: 0.997\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0542 - accuracy: 0.9801\n",
      "Training Accuracy: 0.997\n",
      "Epoch 57/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0522 - accuracy: 0.9808\n",
      "Training Accuracy: 0.997\n",
      "Epoch 58/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0508 - accuracy: 0.9818\n",
      "Training Accuracy: 0.998\n",
      "Set best train accuracy to: 0.998\n",
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0485 - accuracy: 0.9824\n",
      "Training Accuracy: 0.997\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0461 - accuracy: 0.9839\n",
      "Training Accuracy: 0.998\n",
      "Epoch 61/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0480 - accuracy: 0.9827\n",
      "Training Accuracy: 0.993\n",
      "Epoch 62/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0446 - accuracy: 0.9833\n",
      "Training Accuracy: 0.993\n",
      "Epoch 63/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0469 - accuracy: 0.9824\n",
      "Training Accuracy: 0.999\n",
      "Set best train accuracy to: 0.999\n",
      "Epoch 64/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0437 - accuracy: 0.9839\n",
      "Training Accuracy: 0.998\n",
      "Epoch 65/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0413 - accuracy: 0.9850\n",
      "Training Accuracy: 0.999\n",
      "Epoch 66/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0409 - accuracy: 0.9848\n",
      "Training Accuracy: 0.999\n",
      "Epoch 67/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0421 - accuracy: 0.9847\n",
      "Training Accuracy: 0.999\n",
      "Epoch 68/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0395 - accuracy: 0.9856\n",
      "Training Accuracy: 0.997\n",
      "Epoch 69/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0385 - accuracy: 0.9856\n",
      "Training Accuracy: 0.999\n",
      "Epoch 70/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0388 - accuracy: 0.9862\n",
      "Training Accuracy: 0.999\n",
      "Epoch 71/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0374 - accuracy: 0.9866\n",
      "Training Accuracy: 0.999\n",
      "Epoch 72/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0343 - accuracy: 0.9882\n",
      "Training Accuracy: 0.999\n",
      "Epoch 73/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0372 - accuracy: 0.9865\n",
      "Training Accuracy: 0.996\n",
      "Epoch 74/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0361 - accuracy: 0.9872\n",
      "Training Accuracy: 0.997\n",
      "Epoch 75/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0342 - accuracy: 0.9879\n",
      "Training Accuracy: 1.000\n",
      "Set best train accuracy to: 1.000\n",
      "Epoch 76/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0321 - accuracy: 0.9883\n",
      "Training Accuracy: 1.000\n",
      "Epoch 77/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0327 - accuracy: 0.9887\n",
      "Training Accuracy: 1.000\n",
      "Epoch 78/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0329 - accuracy: 0.9882\n",
      "Training Accuracy: 1.000\n",
      "Epoch 79/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0309 - accuracy: 0.9892\n",
      "Training Accuracy: 1.000\n",
      "Epoch 80/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0310 - accuracy: 0.9888\n",
      "Training Accuracy: 1.000\n",
      "Epoch 81/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0301 - accuracy: 0.9896\n",
      "Training Accuracy: 0.999\n",
      "Epoch 82/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0296 - accuracy: 0.9893\n",
      "Training Accuracy: 1.000\n",
      "Epoch 83/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0308 - accuracy: 0.9890\n",
      "Training Accuracy: 1.000\n",
      "Epoch 84/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0297 - accuracy: 0.9895\n",
      "Training Accuracy: 1.000\n",
      "Epoch 85/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0286 - accuracy: 0.9896\n",
      "Training Accuracy: 1.000\n",
      "Epoch 86/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0295 - accuracy: 0.9890\n",
      "Training Accuracy: 1.000\n",
      "Epoch 87/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0288 - accuracy: 0.9892\n",
      "Training Accuracy: 0.999\n",
      "Epoch 88/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0282 - accuracy: 0.9898\n",
      "Training Accuracy: 1.000\n",
      "Epoch 89/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0268 - accuracy: 0.9903\n",
      "Training Accuracy: 0.999\n",
      "Epoch 90/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0260 - accuracy: 0.9909\n",
      "Training Accuracy: 1.000\n",
      "Epoch 91/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0260 - accuracy: 0.9908\n",
      "Training Accuracy: 1.000\n",
      "Epoch 92/1000\n",
      "60000/60000 [==============================] - 32s 525us/step - loss: 0.0247 - accuracy: 0.9913\n",
      "Training Accuracy: 1.000\n",
      "Epoch 93/1000\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.0256 - accuracy: 0.9906\n",
      "Training Accuracy: 1.000\n",
      "Epoch 94/1000\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.0240 - accuracy: 0.9919\n",
      "Training Accuracy: 1.000\n",
      "Epoch 95/1000\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.0248 - accuracy: 0.9913\n",
      "Training Accuracy: 1.000\n",
      "Epoch 96/1000\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0250 - accuracy: 0.9915\n",
      "Training Accuracy: 1.000\n",
      "Epoch 97/1000\n",
      "60000/60000 [==============================] - 28s 459us/step - loss: 0.0234 - accuracy: 0.9920\n",
      "Training Accuracy: 1.000\n",
      "Epoch 98/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0243 - accuracy: 0.9914\n",
      "Training Accuracy: 1.000\n",
      "Epoch 99/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0220 - accuracy: 0.9919\n",
      "Training Accuracy: 1.000\n",
      "Epoch 100/1000\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0218 - accuracy: 0.9923\n",
      "Training Accuracy: 1.000\n",
      "Epoch 101/1000\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0226 - accuracy: 0.9921\n",
      "Training Accuracy: 1.000\n",
      "Epoch 102/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0229 - accuracy: 0.9918\n",
      "Training Accuracy: 1.000\n",
      "Epoch 103/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0215 - accuracy: 0.9924\n",
      "Training Accuracy: 1.000\n",
      "Epoch 104/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0217 - accuracy: 0.9924\n",
      "Training Accuracy: 1.000\n",
      "Epoch 105/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0197 - accuracy: 0.9932\n",
      "Training Accuracy: 1.000\n",
      "Epoch 106/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0214 - accuracy: 0.9922\n",
      "Training Accuracy: 1.000\n",
      "Epoch 107/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0204 - accuracy: 0.9930\n",
      "Training Accuracy: 1.000\n",
      "Epoch 108/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0202 - accuracy: 0.9927\n",
      "Training Accuracy: 1.000\n",
      "Epoch 109/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0205 - accuracy: 0.9930\n",
      "Training Accuracy: 1.000\n",
      "Epoch 110/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0203 - accuracy: 0.9931\n",
      "Training Accuracy: 0.999\n",
      "Epoch 111/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0179 - accuracy: 0.9938\n",
      "Training Accuracy: 1.000\n",
      "Epoch 112/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0194 - accuracy: 0.9930\n",
      "Training Accuracy: 1.000\n",
      "Epoch 113/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0190 - accuracy: 0.9934\n",
      "Training Accuracy: 1.000\n",
      "Epoch 114/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0205 - accuracy: 0.9930\n",
      "Training Accuracy: 1.000\n",
      "Epoch 115/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0192 - accuracy: 0.9934\n",
      "Training Accuracy: 0.999\n",
      "Epoch 116/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0180 - accuracy: 0.9940\n",
      "Training Accuracy: 1.000\n",
      "Epoch 117/1000\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Training Accuracy: 1.000\n",
      "Epoch 118/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0176 - accuracy: 0.9938\n",
      "Training Accuracy: 1.000\n",
      "Epoch 119/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0177 - accuracy: 0.9939\n",
      "Training Accuracy: 1.000\n",
      "Epoch 120/1000\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0173 - accuracy: 0.9940\n",
      "Training Accuracy: 1.000\n",
      "Epoch 121/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0168 - accuracy: 0.9943\n",
      "Training Accuracy: 1.000\n",
      "Epoch 122/1000\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0167 - accuracy: 0.9944\n",
      "Training Accuracy: 1.000\n",
      "Epoch 123/1000\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Training Accuracy: 1.000\n",
      "Epoch 124/1000\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0164 - accuracy: 0.9944\n",
      "Training Accuracy: 1.000\n",
      "Epoch 125/1000\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0177 - accuracy: 0.9935\n",
      "Training Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "class CustomEarlyStopping(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0, threshold=1):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best_trn_acc = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        trn_acc = self.model.evaluate(trn.X, trn.Y, batch_size=32, verbose=0)[1]       \n",
    "        print('Training Accuracy: %0.03f'%trn_acc)\n",
    "        if np.greater(np.round(trn_acc,3), np.round(self.best_trn_acc,3)):\n",
    "            print('Set best train accuracy to: %0.03f'%trn_acc)\n",
    "            self.best_trn_acc = trn_acc\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "custom_ES = CustomEarlyStopping(patience=50)\n",
    "lr_decay = ReduceLROnPlateau(monitor='accuracy', factor=0.9, patience=10, verbose=1)\n",
    "\n",
    "r = model.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 1, \n",
    "              batch_size = cfg['batch_size'],\n",
    "              epochs = cfg['n_epochs'],\n",
    "              callbacks = [custom_ES, lr_decay])\n",
    "\n",
    "model.save(cfg['exp_name']+\"/model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d679ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the train and test set:\n",
      "60000/60000 [==============================] - 9s 152us/step\n",
      "10000/10000 [==============================] - 2s 151us/step\n",
      "Train loss = 0.006; Train accuracy = 1.000\n",
      "Test loss = 0.273; Test accuracy = 0.931\n",
      "Saving generalization/CNN_Global_Fashion_MNIST/CNN_Global_512-512-512-512_Fashion_MNIST_SGD_BatchNorm_True-True-True-True_Dropout_0.4-0.4-0.4-0.4/run_1/metrics\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "print('Evaluating the model on the train and test set:')\n",
    "trn_results = model.evaluate(trn.X, trn.Y, batch_size=32, verbose=1)\n",
    "train_loss = trn_results[0]\n",
    "train_acc = trn_results[1]\n",
    "tst_results = model.evaluate(tst.X, tst.Y, batch_size=32, verbose=1)\n",
    "test_loss = tst_results[0]\n",
    "test_acc = tst_results[1]\n",
    "print('Train loss = %0.03f; Train accuracy = %0.03f'%(train_loss, train_acc))\n",
    "print('Test loss = %0.03f; Test accuracy = %0.03f'%(test_loss, test_acc))\n",
    "\n",
    "metrics={}\n",
    "metrics['train_loss'] = train_loss\n",
    "metrics['train_acc'] = train_acc\n",
    "metrics['test_loss'] = test_loss\n",
    "metrics['test_acc'] = test_acc\n",
    "\n",
    "fname = cfg['exp_name']+'/metrics'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(metrics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fbd09491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMI:0.305\n",
      "Saving generalization/CNN_Global_Fashion_MNIST/CNN_Global_512-512-512-512_Fashion_MNIST_SGD_BatchNorm_True-True-True-True_Dropout_0.4-0.4-0.4-0.4/run_1/smi\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "int_model = keras.Model(inputs=model.inputs, outputs=model.layers[-4].output)\n",
    "activity = int_model.predict(trn.X[:10000], batch_size=32)\n",
    "if len(activity.shape) > 2:\n",
    "    activity = activity.reshape(activity.shape[0],-1)\n",
    "smi = ee.compute_smi(x=activity, y=trn.y[:10000], m=1000)\n",
    "print(f'SMI:{smi:.3f}')\n",
    "\n",
    "fname = cfg['exp_name']+'/smi'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(smi, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f407ec",
   "metadata": {},
   "source": [
    "### 3. Vary Label Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3193217",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {}\n",
    "cfg['dataset'] = 'Fashion_MNIST'\n",
    "cfg['model'] = 'CNN_Global'\n",
    "cfg['width'] = [512,512,512,512]\n",
    "cfg['optimizer'] = 'SGD'\n",
    "cfg['learning_rate'] = 0.01\n",
    "cfg['batch_size']    = 32\n",
    "cfg['n_epochs'] = 1000\n",
    "cfg['n_train'] = None\n",
    "\n",
    "cfg['dropout'] = []\n",
    "cfg['weight_decay'] = []\n",
    "cfg['batch_norm'] = [True,True,True,True]\n",
    "cfg['noise_ratio'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fc35087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directory generalization/CNN_Global_512-512-512-512_CIFAR10_SGD_WD_0.0001-0.0001-0.0001-0.0001/run_1\n"
     ]
    }
   ],
   "source": [
    "run = 1\n",
    "arch =  '-'.join(map(str,cfg['width']))\n",
    "exp_name = 'generalization/'+cfg['model']+'_'+cfg['dataset']+'/'+cfg['model']+'_'+arch+'_'+cfg['dataset']+'_'+cfg['optimizer']\n",
    "if len(cfg['dropout']) > 0:\n",
    "    dropout =  '-'.join(map(str,cfg['dropout']))\n",
    "    exp_name += '_Dropout_'+dropout\n",
    "if len(cfg['batch_norm']) > 0:\n",
    "    bn =  '-'.join(map(str,cfg['batch_norm']))\n",
    "    exp_name += '_BatchNorm_'+bn\n",
    "if cfg['noise_ratio'] > 0:\n",
    "    exp_name += '_LabelNoise_'+str(cfg['noise_ratio'])\n",
    "cfg['exp_name'] = exp_name + '/run_%d'%(run)\n",
    "if not os.path.exists(cfg['exp_name']):\n",
    "    print(\"Making directory\", cfg['exp_name'])\n",
    "    os.makedirs(cfg['exp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90b8d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = cfg['exp_name'] + '/config.json'\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f61fe213",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = datasets.get_dataset(cfg)\n",
    "\n",
    "if cfg['noise_ratio'] > 0:\n",
    "    with open(cfg['exp_name']+'/noisy_trn', 'wb') as f:\n",
    "        pickle.dump(trn._asdict(), f, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(cfg['exp_name']+'/tst', 'wb') as f:\n",
    "        pickle.dump(tst._asdict(), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "856177fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 15, 15, 512)       14336     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 4, 4, 10)          5130      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_13  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,098,890\n",
      "Trainable params: 7,098,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.get_model(cfg, trn)\n",
    "model.save(cfg['exp_name']+\"/model_initial\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a2f0187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 2.1999 - accuracy: 0.2347\n",
      "Training Accuracy: 0.306\n",
      "Set best train accuracy to: 0.306\n",
      "Epoch 2/1000\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.9173 - accuracy: 0.3540\n",
      "Training Accuracy: 0.382\n",
      "Set best train accuracy to: 0.382\n",
      "Epoch 3/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.7530 - accuracy: 0.4172\n",
      "Training Accuracy: 0.457\n",
      "Set best train accuracy to: 0.457\n",
      "Epoch 4/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.6307 - accuracy: 0.4641\n",
      "Training Accuracy: 0.475\n",
      "Set best train accuracy to: 0.475\n",
      "Epoch 5/1000\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.5257 - accuracy: 0.5068\n",
      "Training Accuracy: 0.524\n",
      "Set best train accuracy to: 0.524\n",
      "Epoch 6/1000\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.4408 - accuracy: 0.5391\n",
      "Training Accuracy: 0.555\n",
      "Set best train accuracy to: 0.555\n",
      "Epoch 7/1000\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.3725 - accuracy: 0.5649\n",
      "Training Accuracy: 0.582\n",
      "Set best train accuracy to: 0.582\n",
      "Epoch 8/1000\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.3064 - accuracy: 0.5886\n",
      "Training Accuracy: 0.614\n",
      "Set best train accuracy to: 0.614\n",
      "Epoch 9/1000\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.2535 - accuracy: 0.6104\n",
      "Training Accuracy: 0.596\n",
      "Epoch 10/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.1913 - accuracy: 0.6353\n",
      "Training Accuracy: 0.636\n",
      "Set best train accuracy to: 0.636\n",
      "Epoch 11/1000\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.1429 - accuracy: 0.6522\n",
      "Training Accuracy: 0.670\n",
      "Set best train accuracy to: 0.670\n",
      "Epoch 12/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.0900 - accuracy: 0.6717\n",
      "Training Accuracy: 0.688\n",
      "Set best train accuracy to: 0.688\n",
      "Epoch 13/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.0350 - accuracy: 0.6923\n",
      "Training Accuracy: 0.682\n",
      "Epoch 14/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.9935 - accuracy: 0.7075\n",
      "Training Accuracy: 0.714\n",
      "Set best train accuracy to: 0.714\n",
      "Epoch 15/1000\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.9462 - accuracy: 0.7243\n",
      "Training Accuracy: 0.724\n",
      "Set best train accuracy to: 0.724\n",
      "Epoch 16/1000\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.9079 - accuracy: 0.7400\n",
      "Training Accuracy: 0.760\n",
      "Set best train accuracy to: 0.760\n",
      "Epoch 17/1000\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.8563 - accuracy: 0.7582\n",
      "Training Accuracy: 0.785\n",
      "Set best train accuracy to: 0.785\n",
      "Epoch 18/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.8183 - accuracy: 0.7698\n",
      "Training Accuracy: 0.797\n",
      "Set best train accuracy to: 0.797\n",
      "Epoch 19/1000\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.7778 - accuracy: 0.7863\n",
      "Training Accuracy: 0.804\n",
      "Set best train accuracy to: 0.804\n",
      "Epoch 20/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.7365 - accuracy: 0.7998\n",
      "Training Accuracy: 0.823\n",
      "Set best train accuracy to: 0.823\n",
      "Epoch 21/1000\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.6907 - accuracy: 0.8179\n",
      "Training Accuracy: 0.813\n",
      "Epoch 22/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.6413 - accuracy: 0.8372\n",
      "Training Accuracy: 0.852\n",
      "Set best train accuracy to: 0.852\n",
      "Epoch 23/1000\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.6137 - accuracy: 0.8466\n",
      "Training Accuracy: 0.865\n",
      "Set best train accuracy to: 0.865\n",
      "Epoch 24/1000\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.5725 - accuracy: 0.8618\n",
      "Training Accuracy: 0.880\n",
      "Set best train accuracy to: 0.880\n",
      "Epoch 25/1000\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.5199 - accuracy: 0.8821\n",
      "Training Accuracy: 0.909\n",
      "Set best train accuracy to: 0.909\n",
      "Epoch 26/1000\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.4916 - accuracy: 0.8913\n",
      "Training Accuracy: 0.914\n",
      "Set best train accuracy to: 0.914\n",
      "Epoch 27/1000\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.4509 - accuracy: 0.9088\n",
      "Training Accuracy: 0.914\n",
      "Epoch 28/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.4157 - accuracy: 0.9212\n",
      "Training Accuracy: 0.936\n",
      "Set best train accuracy to: 0.936\n",
      "Epoch 29/1000\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.3871 - accuracy: 0.9331\n",
      "Training Accuracy: 0.961\n",
      "Set best train accuracy to: 0.961\n",
      "Epoch 30/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.3423 - accuracy: 0.9488\n",
      "Training Accuracy: 0.968\n",
      "Set best train accuracy to: 0.968\n",
      "Epoch 31/1000\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.3204 - accuracy: 0.9580\n",
      "Training Accuracy: 0.978\n",
      "Set best train accuracy to: 0.978\n",
      "Epoch 32/1000\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2909 - accuracy: 0.9689\n",
      "Training Accuracy: 0.982\n",
      "Set best train accuracy to: 0.982\n",
      "Epoch 33/1000\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.2691 - accuracy: 0.9770\n",
      "Training Accuracy: 0.986\n",
      "Set best train accuracy to: 0.986\n",
      "Epoch 34/1000\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2606 - accuracy: 0.9795\n",
      "Training Accuracy: 0.982\n",
      "Epoch 35/1000\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2603 - accuracy: 0.9801\n",
      "Training Accuracy: 0.995\n",
      "Set best train accuracy to: 0.995\n",
      "Epoch 36/1000\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2310 - accuracy: 0.9910\n",
      "Training Accuracy: 0.997\n",
      "Set best train accuracy to: 0.997\n",
      "Epoch 37/1000\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.2160 - accuracy: 0.9944\n",
      "Training Accuracy: 0.993\n",
      "Epoch 38/1000\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.2344 - accuracy: 0.9881\n",
      "Training Accuracy: 0.984\n",
      "Epoch 39/1000\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.2216 - accuracy: 0.9924\n",
      "Training Accuracy: 0.994\n",
      "Epoch 40/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2121 - accuracy: 0.9953\n",
      "Training Accuracy: 1.000\n",
      "Set best train accuracy to: 1.000\n",
      "Epoch 41/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1909 - accuracy: 0.9999\n",
      "Training Accuracy: 1.000\n",
      "Epoch 42/1000\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1860 - accuracy: 0.9999\n",
      "Training Accuracy: 1.000\n",
      "Epoch 43/1000\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1830 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 44/1000\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.1804 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 45/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1779 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 46/1000\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1755 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 47/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1732 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 48/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1709 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 49/1000\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1688 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n",
      "Epoch 50/1000\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1667 - accuracy: 1.0000\n",
      "Training Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "class CustomEarlyStopping(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0, threshold=1):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best_trn_acc = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        trn_acc = self.model.evaluate(trn.X, trn.Y, batch_size=32, verbose=0)[1]       \n",
    "        print('Training Accuracy: %0.03f'%trn_acc)\n",
    "        if np.greater(np.round(trn_acc,3), np.round(self.best_trn_acc,3)):\n",
    "            print('Set best train accuracy to: %0.03f'%trn_acc)\n",
    "            self.best_trn_acc = trn_acc\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "custom_ES = CustomEarlyStopping(patience=50)\n",
    "lr_decay = ReduceLROnPlateau(monitor='accuracy', factor=0.9, patience=10, verbose=1)\n",
    "\n",
    "r = model.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 1, \n",
    "              batch_size = cfg['batch_size'],\n",
    "              epochs = cfg['n_epochs'],\n",
    "              callbacks = [custom_ES, lr_decay])\n",
    "\n",
    "model.save(cfg['exp_name']+\"/model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e052d89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the train and test set:\n",
      "50000/50000 [==============================] - 8s 158us/step\n",
      "10000/10000 [==============================] - 2s 158us/step\n",
      "Train loss = 0.195; Train accuracy = 1.000\n",
      "Test loss = 1.429; Test accuracy = 0.750\n",
      "Saving generalization/CNN_Global_512-512-512-512_CIFAR10_SGD_WD_0.0001-0.0001-0.0001-0.0001/run_1/metrics\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "\n",
    "if cfg['noise_ratio'] > 0:\n",
    "    Dataset = namedtuple('Dataset',['X','Y','y'])\n",
    "    with open(cfg['exp_name']+'/noisy_trn', 'rb') as f:\n",
    "        trn = Dataset(**pickle.load(f))\n",
    "    with open(cfg['exp_name']+'/tst', 'rb') as f:\n",
    "        tst = Dataset(**pickle.load(f))\n",
    "\n",
    "print('Evaluating the model on the train and test set:')\n",
    "trn_results = model.evaluate(trn.X, trn.Y, batch_size=32, verbose=1)\n",
    "train_loss = trn_results[0]\n",
    "train_acc = trn_results[1]\n",
    "tst_results = model.evaluate(tst.X, tst.Y, batch_size=32, verbose=1)\n",
    "test_loss = tst_results[0]\n",
    "test_acc = tst_results[1]\n",
    "print('Train loss = %0.03f; Train accuracy = %0.03f'%(train_loss, train_acc))\n",
    "print('Test loss = %0.03f; Test accuracy = %0.03f'%(test_loss, test_acc))\n",
    "\n",
    "metrics={}\n",
    "metrics['train_loss'] = train_loss\n",
    "metrics['train_acc'] = train_acc\n",
    "metrics['test_loss'] = test_loss\n",
    "metrics['test_acc'] = test_acc\n",
    "\n",
    "fname = cfg['exp_name']+'/metrics'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(metrics, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9be08c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMI:0.034\n",
      "Saving generalization/CNN_Global_512-512-512-512_CIFAR10_SGD_WD_0.0001-0.0001-0.0001-0.0001/run_1/smi\n"
     ]
    }
   ],
   "source": [
    "if cfg['noise_ratio'] > 0:\n",
    "    Dataset = namedtuple('Dataset',['X','Y','y'])\n",
    "    with open(cfg['exp_name']+'/noisy_trn', 'rb') as f:\n",
    "        trn = Dataset(**pickle.load(f))\n",
    "        \n",
    "noisy_label = trn.Y.argmax(1)\n",
    "\n",
    "model = keras.models.load_model(cfg['exp_name']+\"/model_final\")\n",
    "int_model = keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
    "activity = int_model.predict(trn.X[:10000], batch_size=32)\n",
    "if len(activity.shape) > 2:\n",
    "    activity = activity.reshape(activity.shape[0],-1)\n",
    "smi = ee.compute_smi(x=activity, y=noisy_label[:10000], m=1000)\n",
    "print(f'SMI:{smi:.3f}')\n",
    "\n",
    "fname = cfg['exp_name']+'/smi'\n",
    "print(\"Saving\", fname)\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(smi, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
